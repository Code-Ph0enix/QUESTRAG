# ğŸ¦ QUESTRAG - Banking QUEries and Support system via Trained Reinforced RAG

[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104.1-green.svg)](https://fastapi.tiangolo.com/)
[![React](https://img.shields.io/badge/React-18.3.1-blue.svg)](https://reactjs.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Deployed on HuggingFace](https://img.shields.io/badge/ğŸ¤—-HuggingFace%20Spaces-yellow)](https://huggingface.co/spaces/eeshanyaj/questrag-backend)

> An intelligent banking chatbot powered by **Retrieval-Augmented Generation (RAG)** and **Reinforcement Learning (RL)** to provide accurate, context-aware responses to Indian banking queries while optimizing token costs.

---

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [Key Features](#key-features)
- [System Architecture](#system-architecture)
- [Technology Stack](#technology-stack)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Datasets](#datasets)
- [Performance Metrics](#performance-metrics)
- [API Documentation](#api-documentation)
- [Deployment](#deployment)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgments](#acknowledgments)
- [Contact](#contact)
- [Status](#status)
- [Links](#links)

---

## ğŸ¯ Overview
QUESTRAG is an **advanced banking chatbot** designed to revolutionize customer support in the Indian banking sector. By combining **Retrieval-Augmented Generation (RAG)** with **Reinforcement Learning (RL)**, the system intelligently decides when to fetch external context from a knowledge base and when to respond directly, **reducing token costs by up to 31%** while maintaining high accuracy.

### Problem Statement
Existing banking chatbots suffer from:
- âŒ Limited response flexibility (rigid, rule-based systems)
- âŒ Poor handling of informal/real-world queries
- âŒ Lack of contextual understanding
- âŒ High operational costs due to inefficient token usage
- âŒ Low user satisfaction and trust

### Solution
QUESTRAG addresses these challenges through:
- âœ… **Domain-specific RAG** trained on 19,000+ banking queries / support data
- âœ… **RL-optimized policy network** (BERT-based) for smart context-fetching decisions
- âœ… **Fine-tuned retriever model** (E5-base-v2) using InfoNCE + Triplet Loss
- âœ… **Groq LLM with HuggingFace fallback** for reliable, fast responses
- âœ… **Full-stack web application** with modern UI/UX and JWT authentication

---

## ğŸŒŸ Key Features

### ğŸ¤– Intelligent RAG Pipeline
- **FAISS-powered retrieval** for fast similarity search across 19,352 documents
- **Fine-tuned embedding model** (`e5-base-v2`) trained on English + Hinglish paraphrases
- **Context-aware response generation** using Llama 3 models (8B & 70B) via Groq

### ğŸ§  Reinforcement Learning System
- **BERT-based policy network** (`bert-base-uncased`) for FETCH/NO_FETCH decisions
- **Reward-driven optimization** (+2.0 accurate, +0.5 needed fetch, -0.5 incorrect)
- **31% token cost reduction** via optimized retrieval

### ğŸ¨ Modern Web Interface
- **React 18 + Vite** with Tailwind CSS
- **Real-time chat**, conversation history, JWT authentication
- **Responsive design** for desktop and mobile

### ğŸ” Enterprise-Ready Backend
- **FastAPI + MongoDB Atlas** for scalable async operations
- **JWT authentication** with secure password hashing (bcrypt)
- **Multi-provider LLM** (Groq â†’ HuggingFace automatic fallback)
- **Deployed on HuggingFace Spaces** with Docker containerization

---

## ğŸ—ï¸ System Architecture

<p align="center">
  <img src="./assets/system.png" alt="System Architecture Diagram" width="750"/>
</p>

### ğŸ”„ Workflow
1. **User Query** â†’ FastAPI receives query via REST API
2. **Policy Decision** â†’ BERT-based RL model decides FETCH or NO_FETCH
3. **Conditional Retrieval** â†’ If FETCH â†’ Retrieve top-5 docs from FAISS using E5-base-v2
4. **Response Generation** â†’ Llama 3 (via Groq) generates final answer
5. **Evaluation & Logging** â†’ Logged in MongoDB + reward-based model update

---

## ğŸ”„ Sequence Diagram

<p align="center">
  <img src="./assets/sequence_diagram.png" alt="Sequence Diagram" width="750"/>
</p>

---

## ğŸ› ï¸ Technology Stack

### **Frontend**
- âš›ï¸ React 18.3.1 + Vite 5.4.2
- ğŸ¨ Tailwind CSS 3.4.1
- ğŸ”„ React Context API + Axios + React Router DOM

### **Backend**
- ğŸš€ FastAPI 0.104.1
- ğŸ—„ï¸ MongoDB Atlas + Motor (async driver)
- ğŸ”‘ JWT Auth + Passlib (bcrypt)
- ğŸ¤– PyTorch 2.9.1, Transformers 4.57, FAISS 1.13.0
- ğŸ’¬ Groq (Llama 3.1 8B Instant / Llama 3.3 70B Versatile)
- ğŸ¯ Sentence Transformers 5.1.2

### **Machine Learning**
- ğŸ§  **Policy Network**: BERT-base-uncased (trained with RL)
- ğŸ” **Retriever**: E5-base-v2 (fine-tuned with InfoNCE + Triplet Loss)
- ğŸ“Š **Vector Store**: FAISS (19,352 documents)

### **Deployment**
- ğŸ³ Docker (HuggingFace Spaces)
- ğŸ¤— HuggingFace Hub (model storage)
- â˜ï¸ MongoDB Atlas (cloud database)
- ğŸŒ Python 3.12 + uvicorn

---

## âš™ï¸ Installation

### ğŸ§© Prerequisites
- Python 3.12+
- Node.js 18+
- MongoDB Atlas account (or local MongoDB 6.0+)
- Groq API key (or HuggingFace token)

### ğŸ”§ Backend Setup (Local Development)

```bash
# Navigate to backend
cd backend

# Create virtual environment
python -m venv venv

# Activate it
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Install dependencies
pip install -r requirements.txt

# Create environment file
cp .env.example .env
# Edit .env with your credentials (see Configuration section)

# Build FAISS index (one-time setup)
python build_faiss_index.py

# Start backend server
uvicorn app.main:app --reload --port 8000
```

### ğŸ’» Frontend Setup

```bash
# Navigate to frontend
cd frontend

# Install dependencies
npm install

# Create environment file
cp .env.example .env
# Update VITE_API_URL to point to your backend

# Start dev server
npm run dev
```

---

## âš™ï¸ Configuration

### ğŸ”‘ Backend `.env` (Key Parameters)

| **Category**      | **Key**                          | **Example / Description**                        |
|-------------------|----------------------------------|--------------------------------------------------|
| Environment       | `ENVIRONMENT`                    | `development` or `production`                    |
| MongoDB           | `MONGODB_URI`                    | `mongodb+srv://user:pass@cluster.mongodb.net/`   |
| Authentication    | `SECRET_KEY`                     | Generate with `python -c "import secrets; print(secrets.token_urlsafe(32))"` |
|                   | `ALGORITHM`                      | `HS256`                                          |
|                   | `ACCESS_TOKEN_EXPIRE_MINUTES`    | `1440` (24 hours)                                |
| Groq API          | `GROQ_API_KEY_1`                 | Your primary Groq API key                        |
|                   | `GROQ_API_KEY_2`                 | Secondary key (optional)                         |
|                   | `GROQ_API_KEY_3`                 | Tertiary key (optional)                          |
|                   | `GROQ_CHAT_MODEL`                | `llama-3.1-8b-instant`                           |
|                   | `GROQ_EVAL_MODEL`                | `llama-3.3-70b-versatile`                        |
| HuggingFace       | `HF_TOKEN_1`                     | HuggingFace token (fallback LLM)                 |
|                   | `HF_MODEL_REPO`                  | `eeshanyaj/questrag_models` (for model download) |
| Model Paths       | `POLICY_MODEL_PATH`              | `app/models/best_policy_model.pth`               |
|                   | `RETRIEVER_MODEL_PATH`           | `app/models/best_retriever_model.pth`            |
|                   | `FAISS_INDEX_PATH`               | `app/models/faiss_index.pkl`                     |
|                   | `KB_PATH`                        | `app/data/final_knowledge_base.jsonl`            |
| Device            | `DEVICE`                         | `cpu` or `cuda`                                  |
| RAG Params        | `TOP_K`                          | `5` (number of documents to retrieve)            |
|                   | `SIMILARITY_THRESHOLD`           | `0.5` (minimum similarity score)                 |
| Policy Network    | `CONFIDENCE_THRESHOLD`           | `0.7` (policy decision confidence)               |
| CORS              | `ALLOWED_ORIGINS`                | `http://localhost:5173` or `*`                   |

### ğŸŒ Frontend `.env`

```bash
# Local development
VITE_API_URL=http://localhost:8000

# Production (HuggingFace Spaces)
VITE_API_URL=https://eeshanyaj-questrag-backend.hf.space
```

---

## ğŸš€ Usage

### ğŸ–¥ï¸ Local Development

#### Start Backend Server

```bash
cd backend
source venv/bin/activate  # or venv\Scripts\activate
uvicorn app.main:app --reload --port 8000
```

- **Backend**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

#### Start Frontend Dev Server

```bash
cd frontend
npm run dev
```

- **Frontend**: http://localhost:5173

### ğŸŒ Production (HuggingFace Spaces)

**Backend API**:
- **Base URL**: https://eeshanyaj-questrag-backend.hf.space
- **API Docs**: https://eeshanyaj-questrag-backend.hf.space/docs
- **Health Check**: https://eeshanyaj-questrag-backend.hf.space/health

**Frontend** (Coming Soon):
- Will be deployed on Vercel/Netlify

---

## ğŸ“ Project Structure

```
questrag/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py              # Auth endpoints (register, login)
â”‚   â”‚   â”‚   â””â”€â”€ chat.py              # Chat endpoints
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_manager.py       # Groq + HF LLM orchestration
â”‚   â”‚   â”‚   â””â”€â”€ security.py          # JWT & password hashing
â”‚   â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”‚   â”œâ”€â”€ policy_network.py    # RL Policy model (BERT)
â”‚   â”‚   â”‚   â””â”€â”€ retriever.py         # E5-base-v2 retriever
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â”œâ”€â”€ mongodb.py           # MongoDB connection
â”‚   â”‚   â”‚   â””â”€â”€ repositories/        # User & conversation repos
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ chat_service.py      # Orchestration logic
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ best_policy_model.pth      # Trained policy network
â”‚   â”‚   â”‚   â”œâ”€â”€ best_retriever_model.pth   # Fine-tuned retriever
â”‚   â”‚   â”‚   â””â”€â”€ faiss_index.pkl            # FAISS vector store
â”‚   â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”‚   â””â”€â”€ final_knowledge_base.jsonl # 19,352 Q&A pairs
â”‚   â”‚   â”œâ”€â”€ config.py                # Settings & env vars
â”‚   â”‚   â””â”€â”€ main.py                  # FastAPI app entry point
â”‚   â”œâ”€â”€ Dockerfile                   # Docker config for HF Spaces
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env.example
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ components/              # UI Components
    â”‚   â”œâ”€â”€ context/                 # Auth Context
    â”‚   â”œâ”€â”€ pages/                   # Login, Register, Chat
    â”‚   â”œâ”€â”€ services/api.js          # Axios Client
    â”‚   â”œâ”€â”€ App.jsx
    â”‚   â””â”€â”€ main.jsx
    â”œâ”€â”€ package.json
    â””â”€â”€ .env
```

---

## ğŸ“Š Datasets

### 1. Final Knowledge Base
- **Size**: 19,352 question-answer pairs
- **Categories**: 15 banking categories
- **Intents**: 22 unique intents (ATM, CARD, LOAN, ACCOUNT, etc.)
- **Source**: Combination of:
  - Bitext Retail Banking Dataset (Hugging Face)
  - RetailBanking-Conversations Dataset
  - Manually curated FAQs from SBI, ICICI, HDFC, Yes Bank, Axis Bank

### 2. Retriever Training Dataset
- **Size**: 11,655 paraphrases
- **Source**: 1,665 unique FAQs from knowledge base
- **Paraphrases per FAQ**:
  - 4 English paraphrases
  - 2 Hinglish paraphrases
  - Original FAQ
- **Training**: InfoNCE Loss + Triplet Loss with E5-base-v2

### 3. Policy Network Training Dataset
- **Size**: 182 queries from 6 chat sessions
- **Format**: (state, action, reward) tuples
- **Actions**: FETCH (1) or NO_FETCH (0)
- **Rewards**: +2.0 (correct), +0.5 (needed fetch), -0.5 (incorrect)

---

## ğŸ“ˆ Performance Metrics

*Coming soon: Detailed performance metrics including accuracy, response time, token cost reduction, and user satisfaction scores.*

---

## ğŸ“š API Documentation

### Authentication

#### Register

```http
POST /api/v1/auth/register
Content-Type: application/json

{
  "username": "john_doe",
  "email": "john@example.com",
  "password": "securepassword123"
}
```

**Response:**

```json
{
  "message": "User registered successfully",
  "user_id": "507f1f77bcf86cd799439011"
}
```

#### Login

```http
POST /api/v1/auth/login
Content-Type: application/json

{
  "username": "john_doe",
  "password": "securepassword123"
}
```

**Response:**

```json
{
  "access_token": "eyJhbGciOiJIUzI1NiIs...",
  "token_type": "bearer"
}
```

---

### Chat

#### Send Message

```http
POST /api/v1/chat/
Authorization: Bearer <token>
Content-Type: application/json

{
  "query": "What are the interest rates for home loans?",
  "conversation_id": "optional-session-id"
}
```

**Response:**

```json
{
  "response": "Current home loan interest rates range from 8.5% to 9.5% per annum...",
  "conversation_id": "abc123",
  "metadata": {
    "policy_action": "FETCH",
    "retrieval_score": 0.89,
    "documents_retrieved": 5,
    "llm_provider": "groq"
  }
}
```

#### Get Conversation History

```http
GET /api/v1/chat/conversations/{conversation_id}
Authorization: Bearer <token>
```

**Response:**

```json
{
  "conversation_id": "abc123",
  "messages": [
    {
      "role": "user",
      "content": "What are the interest rates?",
      "timestamp": "2025-11-28T10:30:00Z"
    },
    {
      "role": "assistant",
      "content": "Current rates are...",
      "timestamp": "2025-11-28T10:30:05Z",
      "metadata": {
        "policy_action": "FETCH"
      }
    }
  ]
}
```

#### List All Conversations

```http
GET /api/v1/chat/conversations
Authorization: Bearer <token>
```

#### Delete Conversation

```http
DELETE /api/v1/chat/conversation/{conversation_id}
Authorization: Bearer <token>
```

---

## ğŸš€ Deployment

### HuggingFace Spaces (Backend)

The backend is deployed on HuggingFace Spaces using Docker:

1. **Models are stored** on HuggingFace Hub: `eeshanyaj/questrag_models`
2. **On first startup**, models are automatically downloaded from HF Hub
3. **Docker container** runs FastAPI with uvicorn on port 7860
4. **Environment secrets** are securely managed in HF Space settings

**Deployment Steps:**

```bash
# 1. Upload models to HuggingFace Hub
huggingface-cli upload eeshanyaj/questrag_models \
  app/models/best_policy_model.pth \
  models/best_policy_model.pth

# 2. Push backend code to HF Space
git remote add space https://huggingface.co/spaces/eeshanyaj/questrag-backend
git push space main

# 3. Add environment secrets in HF Space Settings
# (MongoDB URI, Groq keys, JWT secret, etc.)
```

### Frontend Deployment (Vercel/Netlify)

```bash
# Build for production
npm run build

# Deploy to Vercel
vercel --prod

# Update .env.production with backend URL
VITE_API_URL=https://eeshanyaj-questrag-backend.hf.space
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines
- Follow PEP 8 for Python code
- Use ESLint + Prettier for JavaScript/React
- Write comprehensive docstrings and comments
- Add unit tests for new features
- Update documentation accordingly

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE)

---

## ğŸ™ Acknowledgments

### Research Inspiration
- **Main Paper**: "Optimizing Retrieval Augmented Generation for Domain-Specific Chatbots with Reinforcement Learning" (AAAI 2024)
- **Additional References**:
  - "Evaluating BERT-based Rewards for Question Generation with RL"
  - "Self-Reasoning for Retrieval-Augmented Language Models"

### Open Source Resources
- [RL-Self-Improving-RAG](https://github.com/subrata-samanta/RL-Self-Improving-RAG)
- [ARENA](https://github.com/ren258/ARENA)
- [RAGTechniques](https://github.com/NirDiamant/RAGTechniques)
- [Financial-RAG-From-Scratch](https://github.com/cse-amarjeet/Financial-RAG-From-Scratch)

### Datasets
- [Bitext Retail Banking Dataset](https://huggingface.co/datasets/bitext/Bitext-retail-banking-llm-chatbot-training-dataset)
- [RetailBanking-Conversations](https://huggingface.co/datasets/oopere/RetailBanking-Conversations)

### Technologies
- [FastAPI](https://fastapi.tiangolo.com/)
- [React](https://reactjs.org/)
- [HuggingFace](https://huggingface.co/)
- [Groq](https://groq.com/)
- [MongoDB Atlas](https://www.mongodb.com/cloud/atlas)

---

## ğŸ“ Contact

**Eeshanya Amit Joshi**  
ğŸ“§ [Email](mailto:eeshanyajoshi@gmail.com)    
ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/eeshanyajoshi/)

---

## ğŸ“ˆ Status

### âœ… **Backend Deployed & Live!**
- ğŸš€ Backend API running on [HuggingFace Spaces](https://eeshanyaj-questrag-backend.hf.space)
- ğŸ“š API Documentation available at [/docs](https://eeshanyaj-questrag-backend.hf.space/docs)
- ğŸ’š Health status: [Check here](https://eeshanyaj-questrag-backend.hf.space/health)

### ğŸš§ **Frontend Deployment - Coming Soon!**
- Will be deployed on Vercel/Netlify
- Stay tuned for full application link! â¤ï¸

---

## ğŸ”— Links

- **Live Backend API:** https://eeshanyaj-questrag-backend.hf.space
- **API Documentation:** https://eeshanyaj-questrag-backend.hf.space/docs
- **Health Check:** https://eeshanyaj-questrag-backend.hf.space/health
- **HuggingFace Space:** https://huggingface.co/spaces/eeshanyaj/questrag-backend
- **Model Repository:** https://huggingface.co/eeshanyaj/questrag_models
- **Research Paper:** [AAAI 2024 Workshop](https://arxiv.org/abs/2401.06800)

---

<p align="center">âœ¨ Made with â¤ï¸ for the Banking Industry âœ¨</p>
<p align="center">Powered by HuggingFace ğŸ¤—| Groq âš¡| MongoDB ğŸƒ| Docker ğŸ³| </p>
